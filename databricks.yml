bundle:
  name: nanba-selective-cicd

variables:
  use_case:
    description: Which use case to deploy
    default: all

# Define resources that will be customized per target
resources:
  jobs:
    # Job for usecase-1
    usecase_1_job:
      name: "UseCase-1 Processing Job"
      tasks:
        - task_key: process_data
          notebook_task:
            notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
            source: WORKSPACE
          # Cluster will be set in each target
      queue:
        enabled: true
      max_concurrent_runs: 1
      
    # Job for usecase-2  
    usecase_2_job:
      name: "UseCase-2 Processing Job"
      tasks:
        - task_key: process_data
          notebook_task:
            notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
            source: WORKSPACE
          # Cluster will be set in each target
      queue:
        enabled: true
      max_concurrent_runs: 1
      
    # Shared/common job
    shared_processing_job:
      name: "Shared Data Processing"
      tasks:
        - task_key: shared_task
          notebook_task:
            notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
            source: WORKSPACE
          # Cluster will be set in each target
      queue:
        enabled: true
      max_concurrent_runs: 1

targets:
  # Development target - deploys everything for PR validation
  dev:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/dev
    
    resources:
      clusters:
        dev-cluster:
          cluster_name: dev-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Development"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_1_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.dev-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
                source: WORKSPACE
        
        usecase_2_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.dev-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.dev-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src  # Deploy entire src directory for dev
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"

  # TEST targets for selective deployment
  test-uc1:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/test
    
    resources:
      clusters:
        test-cluster:
          cluster_name: test-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Testing"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_1_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-1
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"

  test-uc2:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/test
    
    resources:
      clusters:
        test-cluster:
          cluster_name: test-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Testing"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_2_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-2
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"

  test-all:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/test
    
    resources:
      clusters:
        test-cluster:
          cluster_name: test-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Testing"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_1_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
                source: WORKSPACE
        
        usecase_2_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.test-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-1
        - ./src/usecase-2
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"

  # PROD targets for selective deployment
  prod-uc1:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/prod
    
    resources:
      clusters:
        prod-cluster:
          cluster_name: prod-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Production"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_1_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-1
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"
    
    permissions:
      - level: CAN_VIEW
        group_name: users

  prod-uc2:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/prod
    
    resources:
      clusters:
        prod-cluster:
          cluster_name: prod-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Production"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_2_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-2
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"
    
    permissions:
      - level: CAN_VIEW
        group_name: users

  prod-all:
    mode: production
    workspace:
      root_path: /Workspace/Deployments/prod
    
    resources:
      clusters:
        prod-cluster:
          cluster_name: prod-cluster
          spark_version: "14.3.x-scala2.12"
          node_type_id: "Standard_DS3_v2"
          num_workers: 0
          autotermination_minutes: 10
          spark_conf:
            "spark.databricks.cluster.profile": "singleNode"
            "spark.master": "local[*]"
          custom_tags:
            Environment: "Production"
            Project: "nanba-selective-cicd"
      
      jobs:
        usecase_1_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-1/This is usecase-1 Notebook"
                source: WORKSPACE
        
        usecase_2_job:
          tasks:
            - task_key: process_data
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/usecase-2/This is usecase-2 Notebook"
                source: WORKSPACE
        
        shared_processing_job:
          tasks:
            - task_key: shared_task
              existing_cluster_id: ${resources.clusters.prod-cluster.cluster_id}
              notebook_task:
                notebook_path: "${workspace.root_path}/files/src/shared/shared_notebook"
                source: WORKSPACE
    
    sync:
      paths:
        - ./src/shared
        - ./src/usecase-1
        - ./src/usecase-2
      exclude:
        - "*.pyc"
        - "__pycache__"
        - ".DS_Store"
        - "*.ipynb_checkpoints"
    
    permissions:
      - level: CAN_VIEW
        group_name: users